# Домашнее задание

Разворачиваем и настраиваем БД с большими данными
**Цель:**
* знать различные механизмы загрузки данных
* уметь пользоваться различными механизмами загрузки данных

Необходимо провести сравнение скорости работы 
запросов на различных СУБД.

1. Выбрать одну из СУБД
2. Загрузить в неё данные (10 Гб)
3. Сравнить скорость выполнения запросов на PosgreSQL и выбранной СУБД
4. Описать что и как делали и с какими проблемами столкнулись

В качестве альтернативной СУБД выбрана MS SQL Server 2019.

## MS SQL:

```bash
gcloud compute instances create mssql --project=unified-firefly-327616 --zone=europe-north1-a --machine-type=e2-standard-4 --network-interface=network-tier=PREMIUM,subnet=default --maintenance-policy=MIGRATE --service-account=486739247397-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --create-disk=auto-delete=yes,boot=yes,device-name=mssql,image=projects/ubuntu-os-cloud/global/images/ubuntu-2004-focal-v20211118,mode=rw,size=250,type=projects/unified-firefly-327616/zones/europe-north1-a/diskTypes/pd-ssd --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any
```

**Загружаем файлы (51 файл суммарным объемом 10ГБ) с данными в ВМ:**
```bash
gsutil -m cp -R gs://taxi_test_dataset .
```
**Ставим MS SQL 2019 и утилиту bcp:**

```bash
sudo apt-get update 
sudo apt install curl

curl https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add -

curl https://packages.microsoft.com/config/ubuntu/20.04/prod.list | sudo tee /etc/apt/sources.list.d/msprod.list

sudo apt-get update 
sudo apt-get install mssql-tools unixodbc-dev

sudo apt-get update 
sudo apt-get install mssql-tools

echo 'export PATH="$PATH:/opt/mssql-tools/bin"' >> ~/.bash_profile
echo 'export PATH="$PATH:/opt/mssql-tools/bin"' >> ~/.bashrc
source ~/.bashrc
```

```bash
sqlcmd -S localhost -U SA -P "123456@Test"
```

**Создаем БД и таблицу:**

```sql
CREATE DATABASE TestDB

CREATE TABLE taxi_trips ( unique_key varchar(100),taxi_id varchar(1000), trip_start_timestamp varchar(40), trip_end_timestamp varchar(40), trip_seconds bigint, trip_miles float, pickup_census_tract bigint, dropoff_census_tract bigint, pickup_community_area bigint, dropoff_community_area bigint, fare float, tips float, tolls float, extras float, trip_total float, payment_type varchar(40), company varchar(1000), pickup_latitude float, pickup_longitude float, pickup_location varchar(1000), dropoff_latitude float, dropoff_longitude float, dropoff_location varchar(1000))
GO
```

**Импортируем данные из файлов в таблицу**

**Для загрузки 1 конкретнго файла:**
```bash
bcp "taxi_trips" in \
    "/home/sig/taxi_test_dataset/part_000000000000" \
    -S localhost \
    -U SA -P "123456@Test" \
    -d TestDB \
    -c \
    -t ","
```
**Загружаем данные из всех файлов в папке:**
```bash
for f in /home/sig/taxi_test_dataset/part* 
do 
	echo -e "Processing $f file..."
    bcp "taxi_trips" in "$f" -S localhost -U SA -P "123456@Test" -d TestDB -c -t ","
done
```
## Результат:

```text
импорт: 24 681 836 строк за 5,68 минут. Максимальная скорость загрузки 105 453 строк/сек
```

**Создадим индекс и выполним запрос:**

```sql
CREATE INDEX IDX_payment_type_INCL ON taxi_trips (payment_type) INCLUDE (tips,trip_total)
GO

set statistics time on
GO

SELECT payment_type,round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent,count(*) as c FROM taxi_trips group by payment_type order by 3
GO
```

```text
payment_type                             tips_percent             c          
---------------------------------------- ------------------------ -----------
Way2ride                                                     15.0          78
Mobile                                                       15.0         779
Pcard                                                         3.0        6794
Prcard                                                        2.0        7365
Dispute                                                       0.0       11111
Unknown                                                       4.0       37506
No Charge                                                     3.0      105813
Credit Card                                                  17.0    10096075
Cash                                                          0.0    14416315

(9 rows affected)

 SQL Server Execution Times:
   CPU time = 15711 ms,  elapsed time = 4249 ms.
```

**Итого: 4 сек. Без индекса я не пробовал выполнять, но уверен, что напорядок больше**

**Кусок плана показывающий, что индекс применяется:**
```text
-1                1.0
24681836                    4                                 |--Index Scan(OBJECT:([TestDB].[dbo].[taxi_trips].[IDX_payment_type_INCL]), ORDERED FORWARD)                                                                                                                                                                                                                                                                                        1           9           8 Index Scan                     Index Scan                     OBJECT:([TestDB].[dbo].[taxi_trips].[IDX_payment_type_INCL]), ORDERED FORWARD                                                                                                                                          [TestDB].[dbo].[taxi_trips].[tips], [TestDB].[dbo].[taxi_trips].[trip_total], [TestDB].[dbo].[taxi_trips].[payment_type]                                                                                                                                                                     2.4681836E+7      92.572754      13.575089          33        106.14784 [TestDB].[dbo].[taxi_trips].[tips], [TestDB].[dbo].[taxi_trips].[trip_total], [TestDB].[dbo].[taxi_trips].[payment_type]              NULL     PLAN_ROW                                                               -1                1.0
```

## Postgres

```bash
gcloud compute instances create postgres --project=unified-firefly-327616 --zone=europe-north1-a --machine-type=e2-standard-4 --network-interface=network-tier=PREMIUM,subnet=default --maintenance-policy=MIGRATE --service-account=486739247397-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --create-disk=auto-delete=yes,boot=yes,device-name=mssql,image=projects/ubuntu-os-cloud/global/images/ubuntu-2004-focal-v20211118,mode=rw,size=250,type=projects/unified-firefly-327616/zones/europe-north1-a/diskTypes/pd-ssd --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any
```

**Загружаем файлы (51 файл суммарным объемом 10ГБ) с данными в ВМ:**
```bash
gsutil -m cp -R gs://taxi_test_dataset .
```
```bash
sudo apt update && sudo DEBIAN_FRONTEND=noninteractive apt upgrade -y -q && sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list' && wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - && sudo apt-get update && sudo DEBIAN_FRONTEND=noninteractive apt -y install postgresql-14
```
```sql
CREATE DATABASE TestDB;
\c TestDB

create table taxi_trips (unique_key text, taxi_id text, trip_start_timestamp TIMESTAMP, trip_end_timestamp TIMESTAMP, trip_seconds bigint, trip_miles numeric, pickup_census_tract bigint, dropoff_census_tract bigint, pickup_community_area bigint, dropoff_community_area bigint, fare numeric, tips numeric, tolls numeric, extras numeric, trip_total numeric, 
payment_type text, company text, pickup_latitude numeric, pickup_longitude numeric, pickup_location text, dropoff_latitude numeric, dropoff_longitude numeric, dropoff_location text);

# Выполним базовую настройку по pgtune:

# DB Version: 14
# OS Type: linux
# DB Type: web
# Total Memory (RAM): 16 GB
# CPUs num: 4
# Connections num: 20
# Data Storage: ssd

ALTER SYSTEM SET
 max_connections = '20';
ALTER SYSTEM SET
 shared_buffers = '4GB';
ALTER SYSTEM SET
 effective_cache_size = '12GB';
ALTER SYSTEM SET
 maintenance_work_mem = '1GB';
ALTER SYSTEM SET
 checkpoint_completion_target = '0.9';
ALTER SYSTEM SET
 wal_buffers = '16MB';
ALTER SYSTEM SET
 default_statistics_target = '100';
ALTER SYSTEM SET
 random_page_cost = '1.1';
ALTER SYSTEM SET
 effective_io_concurrency = '200';
ALTER SYSTEM SET
 work_mem = '104857kB';
ALTER SYSTEM SET
 min_wal_size = '1GB';
ALTER SYSTEM SET
 max_wal_size = '4GB';
ALTER SYSTEM SET
 max_worker_processes = '4';
ALTER SYSTEM SET
 max_parallel_workers_per_gather = '2';
ALTER SYSTEM SET
 max_parallel_workers = '4';
ALTER SYSTEM SET
 max_parallel_maintenance_workers = '2';
```
 ```bash
sudo pg_ctlcluster 14 main restart;
```

 ```bash
for f in /home/sig/taxi_test_dataset/part* 
do
	echo -e "Processing $f file..."
	psql "host=localhost port=5432 dbname=testdb user=postgres password=123456@Test sslmode=require" -c "\\COPY taxi_trips FROM PROGRAM 'cat $f' CSV HEADER"
done
```

## Результат:

```text
импорт: 24 964 210 строк ~ за 4 минуты.
```

```sql
CREATE INDEX IDX_payment_type_INCL ON taxi_trips (payment_type) INCLUDE (tips,trip_total);

\timing on

SELECT payment_type,round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent,count(*) as c FROM taxi_trips group by payment_type order by 3;
```

```text
 payment_type | tips_percent |    c     
--------------+--------------+----------
 Way2ride     |           15 |       78
 Prepaid      |            0 |      104
 Pcard        |            3 |     6877
 Dispute      |            0 |    18034
 Mobile       |           16 |   106482
 Prcard       |            1 |   108324
 Unknown      |            1 |   124809
 No Charge    |            3 |   152502
 Credit Card  |           17 | 10000000
 Cash         |            0 | 14447000
(10 rows)

Time: 4588.750 ms (00:04.589)

 Sort  (cost=498053.25..498053.27 rows=8 width=47)
   Sort Key: (count(*))
   ->  Finalize GroupAggregate  (cost=1000.59..498053.13 rows=8 width=47)
         Group Key: payment_type
         ->  Gather Merge  (cost=1000.59..498052.69 rows=16 width=79)
               Workers Planned: 2
               ->  Partial GroupAggregate  (cost=0.56..497050.82 rows=8 width=79)
                     Group Key: payment_type
                     ->  Parallel Index Only Scan using idx_payment_type_incl on taxi_trips  (cost=0.56..392717.50 rows=10433320 width=17)
 JIT:
   Functions: 6
   Options: Inlining false, Optimization false, Expressions true, Deforming true

```
## ВЫВОД: Скорость загрузки данных из csv файла у утилиты COPY(PG) выше, чем у bcp(MSSQL). Скорость выполнения запроса при наличии индекса примерно одинакова.

